\section{Models and Methods}

\subsection{Preprocessing}

\input{chapters/preprocessing}

\subsection{Machine learning methods}
\label{sec:methods}

\subsubsection{Library Review}

The surprise library was chosen
for its high performance thanks to customizability, great ease of startup
 (installation \& system requriements), ease of use and big variety of
 implemented algorithms for recommender systems.

 TODO: insert links/references
\begin{table}
  \centering
\begin{tabular}{|l|c|c|c|c|}
  \hline
   & startup & ease of use & performance & variety \\
  \hline 
  graphlab   & \two & \thr & \one & \two \\
  pyspark     & \one & \one & \two & \thr \\
  surprise    & \thr & \thr & \thr & \two \\
  fancyinput  & \thr & \thr & \two & \one \\
  \hline 
\end{tabular}
  \caption{Overview of libraries tested for recommender system implementation.
  One star corresponds to lowest performance. }
  \label{tab:libraries}
\end{table}

The goal is to factorize the given ratings matrix using two low-rank matrices, 
\begin{equation}
  \fat{X} = \fat{W}\fat{Z}^T \with \fat{W} \inR{N \times K},
  \fat{Z} \inR{D \times K}, 
\end{equation}
where $K$ is the number of latent features, and \fat{Z} and \fat{W} are in the following
referred to as the user and feature matrix respectively.

Find more about these methods in \cite{Aberger2009}

\subsubsection{Bias Stochastic Gradient Descent}

\input{chapters/methods-sgd}

\subsubsection{Alternating Least Squares}

\input{chapters/methods-als}

\subsection{Blending}

\input{chapters/methods-blending}

\subsection{Evaluation}

\begin{enumerate}
  \item TODO: write about why kaggle results tend to be different than lcoal data for
    SGD, but not for ALS.
  \item \textbf{Cross valdiation} A 10-fold cross validation is implemented
    for the whole training dataset to fix the hyperparameters. 

  \item \textbf{Performance prediction} The training data was split into two
    sets of ratio 1:2, emulating the actual data ratio between Kaggle's training
    and test set. Doing the matrix factorization with this training/test set
    pair enables us to predict if we can expect a better performance on the
    kaggle dataset.  
    TODO: what is this ratio for this dataset? 
\end{enumerate}

