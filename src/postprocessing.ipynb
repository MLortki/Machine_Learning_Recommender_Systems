{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import numpy as np\n",
    "from helpers import load_data\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# trained on whole dataset:\n",
    "#'../submission/train_surprise_unrounded_0.99256.csv'\n",
    "files_full_submission = [ \\\n",
    "    'training_prediction_ALS_BaselineOnly.csv',\\\n",
    "    'training_prediction_KNNBasic_ALS_pearson_baseline_item_based.csv',\\\n",
    "    'training_prediction_KNNBasic_ALS_pearson_baseline_user_based.csv',\\\n",
    "    'training_prediction_KNNBasic_pearson_baseline_user_based.csv',\\\n",
    "    'training_prediction_SGD_BaselineOnly.csv'\n",
    "    ]\n",
    "files_submission = [ \\\n",
    "    'submission_ALS_BaselineOnly.csv',\\\n",
    "    'submission_KNNBasic_ALS_pearson_baseline_item_based.csv',\\\n",
    "    'submission_KNNBasic_ALS_pearson_baseline_user_based.csv',\\\n",
    "    'submission_KNNBasic_pearson_baseline_user_based.csv',\\\n",
    "    'submission_SGD_BaselineOnly.csv'\n",
    "                    ]\n",
    "#files_submission = [ \\\n",
    "#        '../submission/submission_surprise_unrounded_0.99256.csv']\n",
    "\n",
    "files_full_numpy = [\\\n",
    "        #'../submission/saved_0.98475.npy',\\\n",
    "        #'../submission/saved_0.984.npy', \\\n",
    "        '../saved/blend_0.06255_8.npy']\n",
    "#errors_submission = [0.98475, 0.984, 0.98431, 0.99256]\n",
    "\n",
    "names = ['ALS', 'ALS_Baseline', 'KNN_ALS_item', 'KNN_ALS_user', 'KNN_user', 'SGD_Baseline']\n",
    "#names = ['ALS','ALS','ALS','SVD surprise']\n",
    "file_train_true = '../data/data_train.csv'\n",
    "file_submission_true = '../data/sampleSubmission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 10000, number of users: 1000\n",
      "number of items: 10000, number of users: 1000\n",
      "number of rows, cols: 1117939\n",
      "number of non-zero elements in matrix 0: 1117939\n",
      "number of items: 10000, number of users: 1000\n",
      "number of rows, cols: 29403\n",
      "number of non-zero elements in matrix 0: 29403\n",
      "number of items: 10000, number of users: 1000\n",
      "number of rows, cols: 29610\n",
      "number of non-zero elements in matrix 0: 29610\n"
     ]
    }
   ],
   "source": [
    "from blending import get_all_indices, read_numpy_files, apply_indices\n",
    "from our_helpers import load_data\n",
    "# Read full matrices \n",
    "train_true = load_data(file_train_true)\n",
    "training_true = apply_indices([train_true], 'train')[0]\n",
    "test_true = apply_indices([train_true], 'test')[0]\n",
    "validation_true = apply_indices([train_true], 'validation')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 10000, number of users: 1000\n",
      "number of rows, cols to read out: 2353904\n",
      "matrix 0\n",
      "dense matrix shape: (10000, 1000)\n",
      "number of non-zero elements in matrix: 2353904\n"
     ]
    }
   ],
   "source": [
    "submission_true = load_data(file_submission_true)\n",
    "indices = get_all_indices(train_true, submission_true)\n",
    "trains_full = read_numpy_files(files_full_numpy, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 10000, number of users: 1000\n",
      "number of rows, cols: 1117939\n",
      "number of non-zero elements in matrix 0: 1117939\n",
      "number of items: 10000, number of users: 1000\n",
      "number of rows, cols: 29403\n",
      "number of non-zero elements in matrix 0: 29403\n",
      "number of items: 10000, number of users: 1000\n",
      "number of rows, cols: 1176952\n",
      "number of non-zero elements in matrix 0: 1176952\n",
      "number of items: 10000, number of users: 1000\n",
      "number of rows, cols: 29610\n",
      "number of non-zero elements in matrix 0: 29610\n"
     ]
    }
   ],
   "source": [
    "# Apply indices.\n",
    "from blending import apply_indices\n",
    "train_est = apply_indices(trains_full, 'train') \n",
    "test_est = apply_indices(trains_full, 'test') \n",
    "submission_est = apply_indices(trains_full, 'submission') \n",
    "validation_est = apply_indices(trains_full, 'validation') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add matrices saved in submission format.\n",
    "from blending import read_submission_files\n",
    "surprise_full = read_submission_files(files_full_submission)\n",
    "surprise_train_est = apply_indices(surprise_full, 'train') \n",
    "surprise_test_est = apply_indices(surprise_full, 'test') \n",
    "surprise_validation_est = apply_indices(surprise_full, 'validation') \n",
    "\n",
    "\n",
    "surprise_submission = read_submission_files(files_submission)\n",
    "\n",
    "for i in range(len(surprise_train_est)):\n",
    "    validation_est.append(surprise_validation_est[i])\n",
    "    train_est.append(surprise_train_est[i])\n",
    "    test_est.append(surprise_test_est[i])\n",
    "    submission_est.append(surprise_submission[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from data_postprocess import create_sparse_matrix_plot\n",
    "# Visualize matrices\n",
    "i_total, ratings_dense = create_sparse_matrix_plot(training_true, '../results/Blending/matrix_train.png')\n",
    "\n",
    "dense_matrices=[]\n",
    "dense_matrices.append(ratings_dense.copy())\n",
    "#j_total, _ = create_matrix_plot(train_true, axis=1)\n",
    "for i,matrix_est in enumerate(train_est):\n",
    "    __, ratings_dense = create_sparse_matrix_plot(matrix_est, '../results/Blending/matrix_{}'.format(i+1))\n",
    "    dense_matrices.append(ratings_dense.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(1,len(dense_matrices)):\n",
    "    diff_matrix = dense_matrices[i]-dense_matrices[0]\n",
    "    print('diff goes from {} to {}'.format(np.max(diff_matrix),np.min(diff_matrix)))\n",
    "    matrix_plot(diff_matrix, '../results/matrix_diff{}.png'.format(i), 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from blending import linear_blending\n",
    "q_hat, x = linear_blending(test_est, submission_est, test_true)\n",
    "print(q_hat)\n",
    "print(len(q_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cutoff = 1000\n",
    "rows,cols,true_values = sp.find(validation_true)\n",
    "file_name = '../results/Blending/matrix_validation.png'\n",
    "title = 'Validation data'\n",
    "i_total, validation_dense = create_sparse_matrix_plot(validation_true, file_name ,cutoff, title)\n",
    "Q = np.empty((len(true_values),len(validation_est)))\n",
    "for i,validation_prediction in enumerate(validation_est):\n",
    "    __,__,predictions = sp.find(validation_prediction)\n",
    "    Q[:,i] = predictions\n",
    "    rmse = np.sqrt(np.sum(np.power(predictions-true_values, 2)) / len(true_values))\n",
    "    print('rmse method {}: {}'.format(i,rmse))\n",
    "    file_name = '../results/Blending/matrix_validation_{}.png'.format(i)\n",
    "    title = 'Method {}, validation error: {:1.5f}, test error: {:1.5f}'.format(names[i], rmse, errors_submission[i])\n",
    "    create_sparse_matrix_plot(validation_prediction, file_name, cutoff, title)\n",
    "    print(predictions - true_values)\n",
    "blending_prediction = np.dot(Q, x) \n",
    "rmse = np.sqrt(np.sum(np.power(blending_prediction-true_values, 2)) / len(true_values))\n",
    "print('blending method: {}'.format(i,rmse))\n",
    "\n",
    "# create sparse matrix from predictions\n",
    "validation_blending = sp.lil_matrix(validation_true.shape)\n",
    "for k, (i,j) in enumerate(zip(rows, cols)):\n",
    "    validation_blending[i,j] = blending_prediction[k]\n",
    "file_name = '../results/Blending/matrix_blending.png'\n",
    "title = 'Method Blending, validation error: {:1.5f}'.format(rmse)\n",
    "test = create_sparse_matrix_plot(validation_blending, file_name, cutoff, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
