{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD.\n",
      "\n",
      "------------\n",
      "Fold 1\n",
      "RMSE: 0.9424\n",
      "------------\n",
      "Fold 2\n",
      "RMSE: 0.9418\n",
      "------------\n",
      "Fold 3\n",
      "RMSE: 0.9431\n",
      "------------\n",
      "------------\n",
      "Mean RMSE: 0.9424\n",
      "------------\n",
      "------------\n",
      "        Fold 1  Fold 2  Fold 3  Mean    \n",
      "RMSE    0.9424  0.9418  0.9431  0.9424  \n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import evaluate\n",
    "\n",
    "# Load the movielens-100k dataset (download it if needed),\n",
    "# and split it into 3 folds for cross-validation.\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "data.split(n_folds=3)\n",
    "\n",
    "# We'll use the famous SVD algorithm.\n",
    "algo = SVD()\n",
    "\n",
    "# Evaluate performances of our algorithm on the dataset.\n",
    "perf = evaluate(algo, data, measures=['RMSE'])\n",
    "\n",
    "perf.items\n",
    "print(perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Retrieve the trainset.\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "# Build an algorithm, and train it.\n",
    "algo = SVD()\n",
    "algo.train(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 196        item: 302        r = 4.00   est = 4.14   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "uid = str(196)  # raw user id (as in the ratings file). They are **strings**!\n",
    "iid = str(302)  # raw item id (as in the ratings file). They are **strings**!\n",
    "\n",
    "# get a prediction for specific users and items.\n",
    "pred = algo.predict(uid, iid, r=4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Retrieve the trainset and the testset.\n",
    "train_reader = Reader(line_format='item rating user', sep=',',skip_lines=1) \n",
    "trainset = Dataset.load_from_file('../data/data_train_surprise.csv',reader=test_reader)\n",
    "trainset = trainset.build_full_trainset()\n",
    "test_reader = Reader(line_format='item rating user', sep=',',skip_lines=1) \n",
    "testset = Dataset.load_from_file('../data/sampleSubmission_surprise.csv',reader=test_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Trainset' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-665e41decd93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0malgo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mpredictions_svd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_svd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./dump_SVD'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_svd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo_svd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kiki/anaconda3/lib/python3.5/site-packages/surprise/prediction_algorithms/algo_base.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, testset, verbose)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         predictions = [self.predict(uid, iid, r, verbose=verbose)\n\u001b[0;32m--> 128\u001b[0;31m                        for (uid, iid, r) in testset]\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Trainset' object is not iterable"
     ]
    }
   ],
   "source": [
    "testset = testset.build_full_trainset()\n",
    "#x = [x for (uid,iid,r) in test] \n",
    "#testset.split(n_folds=3)\n",
    "# Build an algorithm, and train it.\n",
    "algo = SVD()\n",
    "algo.train(trainset)\n",
    "predictions_svd = algo.test(testset)\n",
    "rmse(predictions_svd)\n",
    "dump('./dump_SVD', predictions_svd, trainset, algo_svd)\n",
    "dump_obj_svd = pickle.load(open('./dump_SVD', 'rb'))\n",
    "\n",
    "# rui: true, est: estimated.\n",
    "df_svd = pd.DataFrame(dump_obj_svd['predictions'], columns=['uid', 'iid', 'rui', 'est', 'details'])    \n",
    "df_svd['err'] = abs(df_svd.est - df_svd.rui)\n",
    "print(df_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save submission\n",
    "df_svd[\"Id\"] = \"r\" + df_svd[\"iid\"].map(str) + \"_c\" +df_svd[\"uid\"].map(str)\n",
    "df_svd[\"Prediction\"] = df_svd[\"est\"].clip(0,5).round()\n",
    "df_svd_new = df_svd.drop([\"iid\",\"uid\",\"est\",\"details\",\"rui\"],1)\n",
    "output_path = '../results/submission_surprise.csv'\n",
    "df_svd_new.to_csv(output_path,columns=[\"Id\",\"Prediction\"],index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 10000, number of users: 1000\n"
     ]
    }
   ],
   "source": [
    "from helpers import load_data\n",
    "import scipy.sparse as sp\n",
    "#ratings = load_data('../data/sampleSubmission.csv')\n",
    "ratings = load_data('../data/data_train.csv')\n",
    "rows, cols, ratings = sp.find(ratings)\n",
    "rows = rows + 1\n",
    "cols = cols + 1\n",
    "test_pd = pd.DataFrame({'item':rows,'user':cols,'rating':ratings})\n",
    "output_path = '../data/data_train_surprise.csv'\n",
    "test_pd.to_csv(output_path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
