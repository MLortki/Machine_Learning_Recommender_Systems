{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "from surprise import Dataset, Reader\n",
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "        Load data from file path\n",
    "    \n",
    "        input:   file_path      -The input file path\n",
    "                \n",
    "        output:  data frame     -The loaded data frame from file path\n",
    "    \"\"\"\n",
    "    reader = Reader(line_format='item rating user', sep=',',skip_lines=1) \n",
    "    return Dataset.load_from_file(file_path, reader=reader)\n",
    "       \n",
    "def load_folds_data(fold_file_paths):\n",
    "    \"\"\"\n",
    "        Load folded data from folded file path\n",
    "    \n",
    "        input:   fold_file_paths  -The file paths of folded data\n",
    "                \n",
    "        output:  fold data frame  -The loaded data frames from folded file path\n",
    "    \"\"\"\n",
    "    reader = Reader(line_format='item rating user', sep=',',skip_lines=1) \n",
    "    return Dataset.load_from_folds(fold_file_paths, reader=reader)\n",
    "    \n",
    "train_data=load_data('../data/data_train_surprise.csv')\n",
    "fold_data=load_folds_data([('../data/blending_validation_surprise.csv', '../data/blending_test_surprise.csv')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from surprise.prediction_algorithms import NormalPredictor\n",
    "from surprise.prediction_algorithms import BaselineOnly\n",
    "from surprise.prediction_algorithms import KNNBasic\n",
    "from surprise.prediction_algorithms import KNNWithMeans\n",
    "from surprise.prediction_algorithms import KNNBaseline\n",
    "from surprise.prediction_algorithms import SVD\n",
    "#from surprise.prediction_algorithms import SVDpp\n",
    "#from surprise.prediction_algorithms import SlopeOne\n",
    "#from surprise.prediction_algorithms import co_clustering\n",
    "\n",
    "#params = {'n_factors':12,'n_epochs':20,'lr_all':0.005,'reg_all':0.0359,'biased':True}\n",
    "#params = {'n_factors':100,'n_epochs':20,'lr_all':0.005,'reg_all':0.0359,'biased':True}\n",
    "def my_SVD(n_factors, n_epochs, lr_all, reg_all, biased):\n",
    "    \"\"\"\n",
    "        SVD method\n",
    "    \n",
    "        input:  n_factors    - The number of factors\n",
    "                n_epochs     - The number of iteration of the SGD procedure\n",
    "                lr_all       - The learning rate for all parameters.\n",
    "                reg_all      - The regularization term for all parameters\n",
    "                biased       - Whether to use baselines (or biases)\n",
    "                \n",
    "        output: algo         - SVD algorithm based on specified parameters \n",
    "    \"\"\"\n",
    "    algo = SVD(n_factors=n_factors,n_epochs=n_epochs,lr_all=lr_all,reg_all=reg_all)\n",
    "    algo.bsl_options['biased'] = biased\n",
    "    return algo\n",
    "\n",
    "def ALS_BaselineOnly():\n",
    "    \"\"\"\n",
    "        BaselineOnly method using ALS\n",
    "        \n",
    "        input:  --      --\n",
    "        output: algo    -BaselineOnly method using ALS\n",
    "    \"\"\"\n",
    "    print(\"ALS_BaselineOnly\")\n",
    "    bsl_options = {'method': 'als',\n",
    "               'n_epochs': 5,\n",
    "               'reg_u': 15,\n",
    "               'reg_i': 10\n",
    "               } #1.0004\n",
    "    return BaselineOnly(bsl_options=bsl_options)\n",
    "\n",
    "def SGD_BaselineOnly():\n",
    "    \"\"\"\n",
    "        BaselineOnly method using ALS\n",
    "        \n",
    "        input:  --      --\n",
    "        output: algo    -BaselineOnly method using SGD\n",
    "    \"\"\"\n",
    "    print(\"SGD_BaselineOnly\")\n",
    "    bsl_options = {'method': 'sgd',\n",
    "               'learning_rate': .005,\n",
    "               'reg':0.02\n",
    "                } #1.0021\n",
    "    return BaselineOnly(bsl_options=bsl_options)\n",
    "\n",
    "\n",
    "def KNNBasic_ALS_pearson_baseline_user_based():\n",
    "    \"\"\"\n",
    "        BaselineOnly method using ALS\n",
    "        \n",
    "        input:  --      --\n",
    "        output: algo    -BaselineOnly method using SGD\n",
    "    \"\"\"\n",
    "    print(\"ALS_pearson_baseline_user_based\")\n",
    "    bsl_options = {'method': 'als',\n",
    "                    'n_epochs': 20,\n",
    "                    'user_based': True  # compute  similarities between users\n",
    "                   } \n",
    "    sim_options = {'name': 'pearson_baseline'}\n",
    "    return KNNBasic(bsl_options=bsl_options, sim_options=sim_options)\n",
    "\n",
    "\n",
    "def KNNBasic_ALS_pearson_baseline_item_based():\n",
    "    print(\"ALS_pearson_baseline_item_based\")\n",
    "    bsl_options = {'method': 'als',\n",
    "               'n_epochs': 20,\n",
    "                'user_based': False  # compute  similarities between users\n",
    "               } \n",
    "    sim_options = {'name': 'pearson_baseline'}\n",
    "    return KNNBasic(bsl_options=bsl_options, sim_options=sim_options)\n",
    "\n",
    "def KNNBasic_pearson_baseline_user_based():\n",
    "    print(\"pearson_baseline_user_based\")\n",
    "    sim_options = {'name': 'pearson_baseline',\n",
    "               'shrinkage': 0,  # no shrinkage\n",
    "                'user_based': True  # compute  similarities between users\n",
    "               } \n",
    "    return KNNBasic(sim_options=sim_options)\n",
    "\n",
    "def KNNBasic_pearson_baseline_item_based():\n",
    "    print(\"pearson_baseline_item_based\")\n",
    "    sim_options = {'name': 'pearson_baseline',\n",
    "               'shrinkage': 0,  # no shrinkage\n",
    "                'user_based': False  # compute  similarities between items\n",
    "               }\n",
    "    return KNNBasic(sim_options=sim_options)\n",
    "\n",
    "\n",
    "def KNNBasic_cosine_user_based():\n",
    "    print(\"cosine_user_based\")\n",
    "    sim_options = {'name': 'cosine',\n",
    "                   'user_based': True  # compute  similarities between users\n",
    "                   }\n",
    "    return KNNBasic(sim_options=sim_options)\n",
    "\n",
    "def KNNBasic_cosine_item_based():\n",
    "    print(\"cosine_item_based\")\n",
    "    sim_options = {'name': 'cosine',\n",
    "                   'user_based': False  # compute  similarities between items\n",
    "                   }\n",
    "    return KNNBasic(sim_options=sim_options)\n",
    "\n",
    "def KNNBasic_pearson_user_based():\n",
    "    print(\"pearson_user_based\")\n",
    "    sim_options = {'name': 'pearson',\n",
    "                'user_based': True  # compute  similarities between users\n",
    "               } \n",
    "    return KNNBasic(sim_options=sim_options)\n",
    "\n",
    "def KNNBasic_pearson_item_based():\n",
    "    print(\"pearson_item_based\")\n",
    "    sim_options = {'name': 'pearson',\n",
    "                'user_based': False  # compute  similarities between items\n",
    "               }\n",
    "    return KNNBasic(sim_options=sim_options)\n",
    "\n",
    "def KNNBasic_msd_user_based():\n",
    "    print(\"msd_user_based\")\n",
    "    sim_options = {'name': 'msd',\n",
    "                'user_based': True  # compute  similarities between users\n",
    "               } \n",
    "    return KNNBasic(sim_options=sim_options)\n",
    "\n",
    "def KNNBasic_msd_item_based():\n",
    "    print(\"msd_item_based\")\n",
    "    sim_options = {'name': 'msd',\n",
    "                'user_based': False  # compute  similarities between items\n",
    "               }\n",
    "    return KNNBasic(sim_options=sim_options)\n",
    "\n",
    "def KNNBaseline_pearson_baseline_user_based():\n",
    "    print(\"pearson_baseline_user_based\")\n",
    "    sim_options = {'name': 'pearson_baseline',\n",
    "               'shrinkage': 0,  # no shrinkage\n",
    "                'user_based': True  # compute  similarities between users\n",
    "               } \n",
    "    return KNNBaseline(sim_options=sim_options)\n",
    "\n",
    "def KNNBaseline_pearson_baseline_item_based():\n",
    "    print(\"pearson_baseline_item_based\")\n",
    "    sim_options = {'name': 'pearson_baseline',\n",
    "               'shrinkage': 0,  # no shrinkage\n",
    "                'user_based': False  # compute  similarities between items\n",
    "               }\n",
    "    return KNNBaseline(sim_options=sim_options)\n",
    "\n",
    "\n",
    "def KNNBaseline_cosine_user_based():\n",
    "    print(\"cosine_user_based\")\n",
    "    sim_options = {'name': 'cosine',\n",
    "                   'user_based': True  # compute  similarities between users\n",
    "                   }\n",
    "    return KNNBaseline(sim_options=sim_options)\n",
    "\n",
    "def KNNBaseline_cosine_item_based():\n",
    "    print(\"cosine_item_based\")\n",
    "    sim_options = {'name': 'cosine',\n",
    "                   'user_based': False  # compute  similarities between items\n",
    "                   }\n",
    "    return KNNBaseline(sim_options=sim_options)\n",
    "\n",
    "def KNNBaseline_pearson_user_based():\n",
    "    print(\"pearson_user_based\")\n",
    "    sim_options = {'name': 'pearson',\n",
    "                'user_based': True  # compute  similarities between users\n",
    "               } \n",
    "    return KNNBaseline(sim_options=sim_options)\n",
    "\n",
    "def KNNBaseline_pearson_item_based():\n",
    "    print(\"pearson_item_based\")\n",
    "    sim_options = {'name': 'pearson',\n",
    "                'user_based': False  # compute  similarities between items\n",
    "               }\n",
    "    return KNNBaseline(sim_options=sim_options)\n",
    "\n",
    "def KNNBaseline_msd_user_based():\n",
    "    print(\"msd_user_based\")\n",
    "    sim_options = {'name': 'msd',\n",
    "                'user_based': True  # compute  similarities between users\n",
    "               } \n",
    "    return KNNBaseline(sim_options=sim_options)\n",
    "\n",
    "def KNNBaseline_msd_item_based():\n",
    "    print(\"msd_item_based\")\n",
    "    sim_options = {'name': 'msd',\n",
    "                'user_based': False  # compute  similarities between items\n",
    "               }\n",
    "    return KNNBaseline(sim_options=sim_options)\n",
    "\n",
    "def KNNWithMeans_pearson_baseline_user_based():\n",
    "    print(\"pearson_baseline_user_based\")\n",
    "    sim_options = {'name': 'pearson_baseline',\n",
    "               'shrinkage': 0,  # no shrinkage\n",
    "                'user_based': True  # compute  similarities between users\n",
    "               } \n",
    "    return KNNWithMeans(sim_options=sim_options)\n",
    "\n",
    "def KNNWithMeans_pearson_baseline_item_based():\n",
    "    print(\"pearson_baseline_item_based\")\n",
    "    sim_options = {'name': 'pearson_baseline',\n",
    "               'shrinkage': 0,  # no shrinkage\n",
    "                'user_based': False  # compute  similarities between items\n",
    "               }\n",
    "    return KNNWithMeans(sim_options=sim_options)\n",
    "\n",
    "\n",
    "def KNNWithMeans_cosine_user_based():\n",
    "    print(\"cosine_user_based\")\n",
    "    sim_options = {'name': 'cosine',\n",
    "                   'user_based': True  # compute  similarities between users\n",
    "                   }\n",
    "    return KNNWithMeans(sim_options=sim_options)\n",
    "\n",
    "def KNNWithMeans_cosine_item_based():\n",
    "    print(\"cosine_item_based\")\n",
    "    sim_options = {'name': 'cosine',\n",
    "                   'user_based': False  # compute  similarities between items\n",
    "                   }\n",
    "    return KNNWithMeans(sim_options=sim_options)\n",
    "\n",
    "def KNNWithMeans_pearson_user_based():\n",
    "    print(\"pearson_user_based\")\n",
    "    sim_options = {'name': 'pearson',\n",
    "                'user_based': True  # compute  similarities between users\n",
    "               } \n",
    "    return KNNWithMeans(sim_options=sim_options)\n",
    "\n",
    "def KNNWithMeans_pearson_item_based():\n",
    "    print(\"pearson_item_based\")\n",
    "    sim_options = {'name': 'pearson',\n",
    "                'user_based': False  # compute  similarities between items\n",
    "               }\n",
    "    return KNNWithMeans(sim_options=sim_options)\n",
    "\n",
    "def KNNWithMeans_msd_user_based():\n",
    "    print(\"msd_user_based\")\n",
    "    sim_options = {'name': 'msd',\n",
    "                'user_based': True  # compute  similarities between users\n",
    "               } \n",
    "    return KNNWithMeans(sim_options=sim_options)\n",
    "\n",
    "def KNNWithMeans_msd_item_based():\n",
    "    print(\"msd_item_based\")\n",
    "    sim_options = {'name': 'msd',\n",
    "                'user_based': False  # compute  similarities between items\n",
    "               }\n",
    "    return KNNWithMeans(sim_options=sim_options)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine_user_based\n",
      "Computing the cosine similarity matrix...\n",
      "1.18222272746\n",
      "1.18222272746\n",
      "mean_rmse 1.1822227274556214\n",
      "Evaluating RMSE of algorithm KNNWithMeans.\n",
      "\n",
      "------------\n",
      "Fold 1\n",
      "Computing the cosine similarity matrix...\n",
      "RMSE: 1.1822\n",
      "------------\n",
      "------------\n",
      "Mean RMSE: 1.1822\n",
      "------------\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "# train algorithm.\n",
    "import numpy as np\n",
    "from surprise.evaluate import evaluate\n",
    "from surprise.accuracy import rmse\n",
    "from surprise.dump import dump\n",
    "\n",
    "    \n",
    "def cross_validation(algo, fold_data):\n",
    "    \"\"\"\n",
    "        Cross validation on folded data by specified algorithm.\n",
    "    \n",
    "        input:   algo           -Learning algorithm method\n",
    "                fold_data      -List of (train_data, test_data) to do cross validation on it\n",
    "                \n",
    "        output:  rmse_mean      -The mean of rmse on all (train_data, test_data) in fold_data\n",
    "                prediction     -The prediction on test_data  \n",
    "    \"\"\"\n",
    "    \n",
    "    rmse_list = []\n",
    "    for trainset, testset in fold_data.folds():\n",
    "        #train the learning model on trainset using given algorithm\n",
    "        algo.train(trainset)\n",
    "        #predcit the result on testset using the trained model\n",
    "        prediction = algo.test(testset)\n",
    "        \n",
    "        #compute rmse\n",
    "        rmse_k = rmse(prediction, verbose=False)\n",
    "        print(rmse_k)\n",
    "        rmse_list.append(rmse_k)\n",
    "        #dump('../results/dump_algo', prediction, trainset, algo)\n",
    "    \n",
    "    \n",
    "    rmse_mean=np.mean(rmse_list)\n",
    "    print(rmse_mean)\n",
    "    return rmse_mean, prediction\n",
    "\n",
    "\n",
    "algo=KNNWithMeans_cosine_user_based()\n",
    "#fold_data=load_folds_data([('../data/blending_train_surprise.csv', '../data/data_train_surprise.csv')])\n",
    "train_data.split(n_folds=3)\n",
    "mean_rmse, prediction=cross_validation(algo, fold_data)\n",
    "print(\"mean_rmse {}\".format(mean_rmse))\n",
    "perf=evaluate(algo, fold_data, measures=['rmse'], with_dump=False, dump_dir=None, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Best parameters of SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing with n_factors=10\n",
      "testing with reg_all=0.012589254117941675\n",
      "testing with n_epochs=10\n",
      "0.998110932578\n",
      "1.00024057624\n",
      "0.998698026239\n",
      "0.999016511687\n",
      "rmse=0.9990165116869073\n",
      "testing with n_epochs=20\n",
      "0.997255685691\n",
      "0.999316921163\n",
      "0.997991556784\n",
      "0.998188054546\n",
      "rmse=0.9981880545460907\n",
      "testing with n_epochs=30\n",
      "0.998026263621\n",
      "1.00006738537\n",
      "0.998811354672\n",
      "0.998968334554\n",
      "rmse=0.9989683345540468\n",
      "testing with n_epochs=40\n",
      "0.998460068363\n",
      "1.00047890125\n",
      "0.999255275174\n",
      "0.999398081596\n",
      "rmse=0.9993980815956767\n",
      "testing with n_epochs=50\n",
      "0.998714935212\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-64620706e6ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mrmses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_SVD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-64620706e6ff>\u001b[0m in \u001b[0;36mtrain_SVD\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0;31m#cross validation on train_data and compute rmse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0mrmses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rmse={}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-457eb7367edd>\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(algo, fold_data)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfold_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m#train the learning model on trainset using given algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;31m#predcit the result on testset using the trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kiki/anaconda3/lib/python3.5/site-packages/surprise/prediction_algorithms/matrix_factorization.pyx\u001b[0m in \u001b[0;36msurprise.prediction_algorithms.matrix_factorization.SVD.train (surprise/prediction_algorithms/matrix_factorization.c:2565)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/kiki/anaconda3/lib/python3.5/site-packages/surprise/prediction_algorithms/matrix_factorization.pyx\u001b[0m in \u001b[0;36msurprise.prediction_algorithms.matrix_factorization.SVD.sgd (surprise/prediction_algorithms/matrix_factorization.c:3546)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/kiki/anaconda3/lib/python3.5/site-packages/surprise/dataset.py\u001b[0m in \u001b[0;36mall_ratings\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_ratings\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mu_ratings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_users\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_SVD():\n",
    "    \"\"\"\n",
    "        Find best parameters for SVD algorithm.\n",
    "       \n",
    "        input:   --      --\n",
    "                \n",
    "        output:  rmses   -The rmse list of running SVD on all parameters set \n",
    "    \"\"\"\n",
    "    \n",
    "    #initialize parameters\n",
    "    n_factors_range = np.array([10,15,20])    #number of columns\n",
    "    reg_all_range = np.logspace(-1.9,-1,10)   #The regularization term for all parameters\n",
    "    n_epochs_range = np.arange(10,60,10)      #The number of iteration of the SGD procedure.\n",
    "    lr_all=0.005                              #The learning rate for all parameters\n",
    "    biased=True                               #use baselines (or biases)\n",
    "    \n",
    "    \n",
    "    results_path = '../results/SGD_surprise/'\n",
    "    rmses = np.empty((len(n_factors_range),len(reg_all_range), len(n_epochs_range)))\n",
    "    \n",
    "    for i,n_factors in enumerate(n_factors_range):\n",
    "        print('testing with n_factors={}'.format(n_factors))\n",
    "        for j,reg_all in enumerate(reg_all_range):\n",
    "            print('testing with reg_all={}'.format(reg_all))\n",
    "            for k,n_epochs in enumerate(n_epochs_range):\n",
    "                print('testing with n_epochs={}'.format(n_epochs))\n",
    "                \n",
    "                #train SVD based on given parameters \n",
    "                algo=my_SVD(int(n_factors), n_epochs, lr_all, reg_all, biased)\n",
    "                \n",
    "                #cross validation on train_data and compute rmse\n",
    "                rmses[i,j,k],_=cross_validation(algo, train_data)\n",
    "                print('rmse={}'.format(rmses[i,j,k]))\n",
    "            \n",
    "            results_name = 'rmse_{}_{}'.format(n_factors, reg_all)\n",
    "            np.savetxt(results_path + results_name + '.csv', rmses[i,j,:], delimiter=\",\")\n",
    "    return rmses\n",
    "\n",
    "train_data.split(n_folds=3)\n",
    "rmses = train_SVD()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# create correct format\n",
    "def create_submission_dataframe(df_simple):\n",
    "    \"\"\"\n",
    "        Convert a data frame in simple format to a data framein submission format\n",
    "      \n",
    "        input:   df_simple      -Data frame in simple format\n",
    "                \n",
    "        output:  df_submission  -Data frame in submission  format\n",
    "    \"\"\"\n",
    "    \n",
    "    #print('Raw: \\n',df_simple.head())\n",
    "    df_simple[\"Id\"] = \"r\" + df_simple[\"iid\"].map(str) + \"_c\" +df_simple[\"uid\"].map(str)\n",
    "    df_simple[\"Prediction\"] = df_simple[\"est\"].clip(0,5)\n",
    "    df_submission = df_simple.drop([\"iid\",\"uid\",\"est\",\"details\",\"rui\"],1)\n",
    "    #print('Submission: \\n',df_submission.head()) \n",
    "    return df_submission\n",
    "\n",
    "def create_submition_csv(prediction, output_path):\n",
    "    \"\"\"save final predictions in output file in csv format\n",
    "    \n",
    "       input:   prediction      -The final prediction\n",
    "                output_path     -The submission file path\n",
    "       \n",
    "       output:  --              -- \n",
    "    \"\"\"\n",
    "    \n",
    "    df_svd = pd.DataFrame(prediction, columns=['uid', 'iid', 'rui', 'est', 'details'])    \n",
    "    df_svd_submission = create_submission_dataframe(df_svd)\n",
    "    df_svd_submission.to_csv(output_path, columns=[\"Id\",\"Prediction\"],index=False)\n",
    "    #print('Submission: \\n', df_svd_submission.head())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on whole data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_and_save(algo, fold_files, output_path):\n",
    "    \"\"\" \n",
    "        Learn the model on trainset based on given algorithm, \n",
    "        predict results on testset, \n",
    "        save the predictions in output file \n",
    "    \n",
    "        input:   algo            -Learning algorithm\n",
    "                fold_filse      -List of file paths of (trainset, testset)\n",
    "                output_path     -Output file path \n",
    "       \n",
    "        output:  mean_rmse       -The mean of rmse on (train_data, test_data) in fold_data\n",
    "       \n",
    "    \"\"\"\n",
    "    \n",
    "    #load train_data and test_data from fold_files list\n",
    "    fold_data=load_folds_data(fold_files)\n",
    "    #do cross validation on (train_data, test_data) and compute rmse and predictions\n",
    "    mean_rmse, prediction = cross_validation(algo, fold_data)\n",
    "    #save prediction in output file path\n",
    "    create_submition_csv(prediction, output_path)\n",
    "    return mean_rmse\n",
    "\n",
    "def run_all_algorithm(fold_files, output_prefix):\n",
    "    \"\"\" \n",
    "        Learn and predict result using diffrenet ML methods\n",
    "    \n",
    "       input:   \n",
    "                fold_filse      -List of file paths of (trainset, testset)\n",
    "                output_prefix   -The prefix of output file path \n",
    "       \n",
    "       output:  rmse_list       -The list of rmse on (train_data, test_data) in fold_data using different ML methods\n",
    "       \n",
    "    \"\"\"\n",
    "    \n",
    "    rmse_list = []\n",
    "    #rmse_list.append(run_and_save(ALS_BaselineOnly(), fold_files, \"../submission/\"+output_prefix+\"ALS_BaselineOnly.csv\"))\n",
    "    #rmse_list.append(run_and_save(SGD_BaselineOnly(), fold_files, \"../submission/\"+output_prefix+\"SGD_BaselineOnly.csv\"))\n",
    "    \n",
    "    #rmse_list.append(run_and_save(KNNBasic_ALS_pearson_baseline_user_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBasic_ALS_pearson_baseline_user_based.csv\"))\n",
    "    #rmse_list.append(run_and_save(KNNBasic_ALS_pearson_baseline_item_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBasic_ALS_pearson_baseline_item_based.csv\"))\n",
    "    \n",
    "    #rmse_list.append(run_and_save(KNNBasic_pearson_baseline_user_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBasic_pearson_baseline_user_based.csv\"))\n",
    "    #rmse_list.append(run_and_save(KNNBasic_pearson_baseline_item_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBasic_pearson_baseline_item_based.csv\"))\n",
    "    #rmse_list.append(run_and_save(KNNBasic_cosine_user_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBasic_cosine_user_based.csv\"))\n",
    "    #rmse_list.append(run_and_save(KNNBasic_cosine_item_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBasic_cosine_item_based.csv\"))\n",
    "    #rmse_list.append(run_and_save(KNNBasic_pearson_user_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBasic_pearson_user_based.csv\"))\n",
    "    #rmse_list.append(run_and_save(KNNBasic_msd_user_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBasic_msd_user_based.csv\"))\n",
    "    #rmse_list.append(run_and_save(KNNBasic_msd_item_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBasic_msd_item_based.csv\"))\n",
    "    \n",
    "    rmse_list.append(run_and_save(KNNWithMeans_pearson_baseline_user_based(), fold_files, \"../submission/\"+output_prefix+\"KNNWithMeans_pearson_baseline_user_based.csv\"))\n",
    "    #rmse_list.append(run_and_save(KNNWithMeans_pearson_baseline_item_based(), fold_files, \"../submission/\"+output_prefix+\"KNNWithMeans_pearson_baseline_item_based.csv\"))\n",
    "    rmse_list.append(run_and_save(KNNWithMeans_cosine_user_based(), fold_files, \"../submission/\"+output_prefix+\"KNNWithMeans_cosine_user_based.csv\"))\n",
    "    rmse_list.append(run_and_save(KNNWithMeans_cosine_item_based(), fold_files, \"../submission/\"+output_prefix+\"KNNWithMeans_cosine_item_based.csv\"))\n",
    "    rmse_list.append(run_and_save(KNNWithMeans_pearson_user_based(), fold_files, \"../submission/\"+output_prefix+\"KNNWithMeans_pearson_user_based.csv\"))\n",
    "    rmse_list.append(run_and_save(KNNWithMeans_msd_user_based(), fold_files, \"../submission/\"+output_prefix+\"KNNWithMeans_msd_user_based.csv\"))\n",
    "    rmse_list.append(run_and_save(KNNWithMeans_msd_item_based(), fold_files, \"../submission/\"+output_prefix+\"KNNWithMeans_msd_item_based.csv\"))\n",
    "    \n",
    "    rmse_list.append(run_and_save(KNNBaseline_pearson_baseline_user_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBaseline_pearson_baseline_user_based.csv\"))\n",
    "    #rmse_list.append(run_and_save(KNNBaseline_pearson_baseline_item_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBaseline_pearson_baseline_item_based.csv\"))\n",
    "    rmse_list.append(run_and_save(KNNBaseline_cosine_user_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBaseline_cosine_user_based.csv\"))\n",
    "    rmse_list.append(run_and_save(KNNBaseline_cosine_item_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBaseline_cosine_item_based.csv\"))\n",
    "    rmse_list.append(run_and_save(KNNBaseline_pearson_user_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBaseline_pearson_user_based.csv\"))\n",
    "    rmse_list.append(run_and_save(KNNBaseline_msd_user_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBaseline_msd_user_based.csv\"))\n",
    "    rmse_list.append(run_and_save(KNNBaseline_msd_item_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBaseline_msd_item_based.csv\"))\n",
    "    \n",
    "    return rmse_list\n",
    "\n",
    "#learn all models on blending train set\n",
    "fold_files=[('../data/blending_train_surprise.csv', '../data/data_train_surprise.csv')]\n",
    "output_prefix='training_prediction_'\n",
    "rmse_list=run_all_algorithm(fold_files, output_prefix)\n",
    "print(\"rmse_list : \")\n",
    "print(rmse_list)\n",
    "\n",
    "#learn all models on whole train set and test on submition set\n",
    "fold_files=[('../data/data_train_surprise.csv', '../data/sampleSubmission_surprise.csv')]\n",
    "output_prefix='submission_'\n",
    "rmse_list = run_all_algorithm(fold_files, output_prefix)\n",
    "print(\"rmse_list : \")\n",
    "print(rmse_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "objects = ('ALS_Baseline', \n",
    "           'SGD_Baseline', \n",
    "           'KNNBasic ALS pearson baseline user based', \n",
    "           'KNNBasic_ALS_pearson_baseline_item_based', \n",
    "           'KNNBasic_pearson_baseline_user_based', \n",
    "           'KNNBasic_pearson_baseline_item_based',\n",
    "           'KNNBasic_cosine_user_based',\n",
    "           'KNNBasic_cosine_item_based',\n",
    "           'KNNBasic_pearson_user_based',\n",
    "           'KNNBasic_msd_user_based',\n",
    "           'KNNBasic_msd_item_based')\n",
    "\n",
    "y_pos=np.arange(11)\n",
    "rmses = [0.99595235614951694, 1.0079698124442131, 0.96028696480475029, \n",
    "         0.96028696480475029, 0.89805490232295371, 0.87317148180816972, \n",
    "         1.2899446549009248, 0.9458979465046482, 0.86038596275603796, 1.0858670369478618, 0.95430388112275488]\n",
    " \n",
    "plt.bar(y_pos, rmses, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Method')\n",
    " \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
