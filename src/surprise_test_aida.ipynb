{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "from surprise import Dataset, Reader\n",
    "def load_data(file_path):\n",
    "    reader = Reader(line_format='item rating user', sep=',',skip_lines=1) \n",
    "    return Dataset.load_from_file(file_path, reader=reader)\n",
    "       \n",
    "def load_folds_data(fold_file_paths):\n",
    "    reader = Reader(line_format='item rating user', sep=',',skip_lines=1) \n",
    "    return Dataset.load_from_folds(fold_file_paths, reader=reader)\n",
    "    \n",
    "train_data=load_data('../data/blending_validation_surprise.csv')\n",
    "fold_data=load_folds_data([('../data/blending_validation_surprise.csv', '../data/blending_test_surprise.csv')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n# nepoch K   lr_all  reg_all  rmse \\n# 120    40  0.001   0.00005  0.9984\\n# 80     40  0.001   0.00005  0.9999 \\n# 80     40  0.01    0.00005  1.0105 \\n# 80     40  0.01    0.02     1.0058\\n# 80     40  0.01    0.2      1.0071 \\n# 40     40  0.001   0.2      1.0042\\n# 80     40  0.001   0.2      1.0043\\n# 120    40  0.001   0.2      1.0047\\n# 40    100  0.001   0.00005  1.0013     \\n# 80    100  0.001   0.0005   1.0017 \\n# 120    100  0.001   0.0005  1.0002 \\n# 120    100  0.001   0.005   \\n# 120    40  0.001   0.0005   1.0016 \\n# 120    40  0.001   0.00001  1.0032 \\n\\nalgo = SVD(n_factors=n_factors,n_epochs=n_epochs,lr_all=lr_all,reg_all=reg_all)\\nalgo.bsl_options['biased'] = biased\\n\\nparams = {'n_factors':12,'n_epochs':20,'lr_all':0.005,'reg_all':0.0359,'biased':True}\\nparams = {'n_factors':100,'n_epochs':20,'lr_all':0.005,'reg_all':0.0359,'biased':True}\\nalgo = SVD(n_factors=params['n_factors'],n_epochs=params['n_epochs'],lr_all=params['lr_all'],reg_all=params['reg_all'])\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "from surprise import KNNBasic\n",
    "from surprise import BaselineOnly\n",
    "\n",
    "#params = {'n_factors':12,'n_epochs':20,'lr_all':0.005,'reg_all':0.0359,'biased':True}\n",
    "#params = {'n_factors':100,'n_epochs':20,'lr_all':0.005,'reg_all':0.0359,'biased':True}\n",
    "def my_SVD(n_factors, n_epochs, lr_all, reg_all, biased):\n",
    "    algo = SVD(n_factors=n_factors,n_epochs=n_epochs,lr_all=lr_all,reg_all=reg_all)\n",
    "    algo.bsl_options['biased'] = biased\n",
    "    return algo\n",
    "\n",
    "def ALS_BaselineOnly():\n",
    "    print(\"ALS_BaselineOnly\")\n",
    "    bsl_options = {'method': 'als',\n",
    "               'n_epochs': 5,\n",
    "               'reg_u': 15,\n",
    "               'reg_i': 10\n",
    "               } #1.0004\n",
    "    return BaselineOnly(bsl_options=bsl_options)\n",
    "\n",
    "def SGD_BaselineOnly():\n",
    "    print(\"SGD_BaselineOnly\")\n",
    "    bsl_options = {'method': 'sgd',\n",
    "               'learning_rate': .005,\n",
    "               'reg':0.02\n",
    "                } #1.0021\n",
    "    return BaselineOnly(bsl_options=bsl_options)\n",
    "\n",
    "\n",
    "def KNNBasic_ALS_pearson_baseline_user_based():\n",
    "    print(\"ALS_pearson_baseline_user_based\")\n",
    "    bsl_options = {'method': 'als',\n",
    "                    'n_epochs': 20,\n",
    "                    'user_based': True  # compute  similarities between users\n",
    "                   } \n",
    "    sim_options = {'name': 'pearson_baseline'}\n",
    "    return KNNBasic(bsl_options=bsl_options, sim_options=sim_options)\n",
    "\n",
    "\n",
    "def KNNBasic_ALS_pearson_baseline_item_based():\n",
    "    print(\"ALS_pearson_baseline_item_based\")\n",
    "    bsl_options = {'method': 'als',\n",
    "               'n_epochs': 20,\n",
    "               } \n",
    "    sim_options = {'name': 'pearson_baseline'}\n",
    "    return KNNBasic(bsl_options=bsl_options, sim_options=sim_options)\n",
    "\n",
    "def KNNBasic_pearson_baseline_user_based():\n",
    "    print(\"pearson_baseline_user_based\")\n",
    "    sim_options = {'name': 'pearson_baseline',\n",
    "               'shrinkage': 0,  # no shrinkage\n",
    "                'user_based': True  # compute  similarities between users\n",
    "               } \n",
    "    return KNNBasic(sim_options=sim_options)\n",
    "\n",
    "def KNNBasic_pearson_baseline_item_based():\n",
    "    print(\"pearson_baseline_item_based\")\n",
    "    sim_options = {'name': 'pearson_baseline',\n",
    "               'shrinkage': 0,  # no shrinkage\n",
    "                'user_based': False  # compute  similarities between items\n",
    "               }\n",
    "    return KNNBasic(sim_options=sim_options)\n",
    "\n",
    "\n",
    "def KNNBasic_cosine_user_based():\n",
    "    print(\"cosine_user_based\")\n",
    "    sim_options = {'name': 'cosine',\n",
    "                   'user_based': True  # compute  similarities between users\n",
    "                   }\n",
    "    return KNNBasic(sim_options=sim_options)\n",
    "\n",
    "def KNNBasic_cosine_item_based():\n",
    "    print(\"cosine_item_based\")\n",
    "    sim_options = {'name': 'cosine',\n",
    "                   'user_based': False  # compute  similarities between items\n",
    "                   }\n",
    "    return KNNBasic(sim_options=sim_options)\n",
    "\n",
    "def KNNBasic_pearson_user_based():\n",
    "    print(\"pearson_user_based\")\n",
    "    sim_options = {'name': 'pearson',\n",
    "                'user_based': True  # compute  similarities between users\n",
    "               } \n",
    "    return KNNBasic(sim_options=sim_options)\n",
    "\n",
    "def KNNBasic_pearson_item_based():\n",
    "    print(\"pearson_item_based\")\n",
    "    sim_options = {'name': 'pearson',\n",
    "                'user_based': False  # compute  similarities between items\n",
    "               }\n",
    "    return KNNBasic(sim_options=sim_options)\n",
    "\n",
    "def KNNBasic_msd_user_based():\n",
    "    print(\"msd_user_based\")\n",
    "    sim_options = {'name': 'msd',\n",
    "                'user_based': True  # compute  similarities between users\n",
    "               } \n",
    "    return KNNBasic(sim_options=sim_options)\n",
    "\n",
    "def KNNBasic_msd_item_based():\n",
    "    print(\"msd_item_based\")\n",
    "    sim_options = {'name': 'msd',\n",
    "                'user_based': False  # compute  similarities between items\n",
    "               }\n",
    "    return KNNBasic(sim_options=sim_options)\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "# nepoch K   lr_all  reg_all  rmse \n",
    "# 120    40  0.001   0.00005  0.9984\n",
    "# 80     40  0.001   0.00005  0.9999 \n",
    "# 80     40  0.01    0.00005  1.0105 \n",
    "# 80     40  0.01    0.02     1.0058\n",
    "# 80     40  0.01    0.2      1.0071 \n",
    "# 40     40  0.001   0.2      1.0042\n",
    "# 80     40  0.001   0.2      1.0043\n",
    "# 120    40  0.001   0.2      1.0047\n",
    "# 40    100  0.001   0.00005  1.0013     \n",
    "# 80    100  0.001   0.0005   1.0017 \n",
    "# 120    100  0.001   0.0005  1.0002 \n",
    "# 120    100  0.001   0.005   \n",
    "# 120    40  0.001   0.0005   1.0016 \n",
    "# 120    40  0.001   0.00001  1.0032 \n",
    "\n",
    "algo = SVD(n_factors=n_factors,n_epochs=n_epochs,lr_all=lr_all,reg_all=reg_all)\n",
    "algo.bsl_options['biased'] = biased\n",
    "\n",
    "params = {'n_factors':12,'n_epochs':20,'lr_all':0.005,'reg_all':0.0359,'biased':True}\n",
    "params = {'n_factors':100,'n_epochs':20,'lr_all':0.005,'reg_all':0.0359,'biased':True}\n",
    "algo = SVD(n_factors=params['n_factors'],n_epochs=params['n_epochs'],lr_all=params['lr_all'],reg_all=params['reg_all'])\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS_BaselineOnly\n",
      "Estimating biases using als...\n",
      "1.04599861118\n",
      "mean_rmse 1.0459986111798536\n",
      "Evaluating RMSE of algorithm BaselineOnly.\n",
      "\n",
      "------------\n",
      "Fold 1\n",
      "Estimating biases using als...\n",
      "RMSE: 1.0460\n",
      "------------\n",
      "------------\n",
      "Mean RMSE: 1.0460\n",
      "------------\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "# train algorithm.\n",
    "import numpy as np\n",
    "from surprise.evaluate import evaluate\n",
    "from surprise.accuracy import rmse\n",
    "from surprise.dump import dump\n",
    "\n",
    "    \n",
    "def cross_validation(algo, fold_data):\n",
    "    rmse_list = []\n",
    "    for trainset, testset in fold_data.folds():\n",
    "        algo.train(trainset)\n",
    "        prediction = algo.test(testset)\n",
    "        rmse_k = rmse(prediction, verbose=False)\n",
    "        rmse_list.append(rmse_k)\n",
    "        #dump('../results/dump_algo', prediction, trainset, algo)\n",
    "        rmse_mean=np.mean(rmse_list)\n",
    "        print(rmse_mean)\n",
    "    return rmse_mean, prediction\n",
    "\n",
    "\n",
    "algo=ALS_BaselineOnly()\n",
    "#fold_data=load_folds_data([('../data/blending_train_surprise.csv', '../data/data_train_surprise.csv')])\n",
    "#train_data.split(n_folds=3)\n",
    "mean_rmse, prediction=cross_validation(algo, fold_data)\n",
    "print(\"mean_rmse {}\".format(mean_rmse))\n",
    "perf=evaluate(algo, fold_data, measures=['rmse'], with_dump=False, dump_dir=None, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Best parameters of SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing with n_factors=10\n",
      "testing with reg_all=0.0125892541179\n",
      "testing with n_epochs=10\n",
      "1.0439708018\n",
      "1.04654341842\n",
      "1.04526873732\n",
      "1.05039099401\n",
      "1.04903610241\n",
      "rmse=1.04903610241\n",
      "testing with n_epochs=20\n",
      "1.04360218027\n",
      "1.04397673835\n",
      "1.04217639919\n",
      "1.04757023967\n",
      "1.04604159515\n",
      "rmse=1.04604159515\n",
      "testing with n_epochs=30\n",
      "1.0505973366\n",
      "1.04916194364\n",
      "1.04694236825\n",
      "1.05214879714\n",
      "1.05069232409\n",
      "rmse=1.05069232409\n",
      "testing with n_epochs=40\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-cbf6fb18a1ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrmses\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mrmses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_SVD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-cbf6fb18a1ff>\u001b[0m in \u001b[0;36mtrain_SVD\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m                 \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'testing with n_epochs={}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                 \u001b[0malgo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmy_SVD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_factors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbiased\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m                 \u001b[0mrmses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcross_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malgo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m                 \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rmse={}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrmses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mresults_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'rmse_{}_{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_factors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-ef7a31005daa>\u001b[0m in \u001b[0;36mcross_validation\u001b[1;34m(algo, fold_data)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mrmse_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestset\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfold_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfolds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0malgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mrmse_k\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrmse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/aida/anaconda2/lib/python2.7/site-packages/surprise/prediction_algorithms/matrix_factorization.pyx\u001b[0m in \u001b[0;36msurprise.prediction_algorithms.matrix_factorization.SVD.train (surprise/prediction_algorithms/matrix_factorization.c:2565)\u001b[1;34m()\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[0mAlgoBase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msgd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msgd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/aida/anaconda2/lib/python2.7/site-packages/surprise/prediction_algorithms/matrix_factorization.pyx\u001b[0m in \u001b[0;36msurprise.prediction_algorithms.matrix_factorization.SVD.sgd (surprise/prediction_algorithms/matrix_factorization.c:3546)\u001b[1;34m()\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m                 \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" Processing epoch {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_ratings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[1;31m# compute current error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/aida/anaconda2/lib/python2.7/site-packages/surprise/dataset.pyc\u001b[0m in \u001b[0;36mall_ratings\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    575\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu_ratings\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miteritems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mur\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mu_ratings\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 577\u001b[1;33m                 \u001b[1;32myield\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    578\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mall_users\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_SVD():\n",
    "    \n",
    "    n_factors_range = np.array([10,15,20])#np.linspace(10,30,21)\n",
    "    reg_all_range = np.logspace(-1.9,-1,10)\n",
    "    n_epochs_range = np.arange(10,60,10)\n",
    "    lr_all=0.005\n",
    "    biased=True\n",
    "    \n",
    "    \n",
    "    results_path = '../results/SGD_surprise/'\n",
    "    rmses = np.empty((len(n_factors_range),len(reg_all_range), len(n_epochs_range)))\n",
    "    \n",
    "    for i,n_factors in enumerate(n_factors_range):\n",
    "        print('testing with n_factors={}'.format(n_factors))\n",
    "        for j,reg_all in enumerate(reg_all_range):\n",
    "            print('testing with reg_all={}'.format(reg_all))\n",
    "            for k,n_epochs in enumerate(n_epochs_range):\n",
    "                print('testing with n_epochs={}'.format(n_epochs))\n",
    "                algo=my_SVD(int(n_factors), n_epochs, lr_all, reg_all, biased)\n",
    "                rmses[i,j,k],_=cross_validation(algo, train_data)\n",
    "                print('rmse={}'.format(rmses[i,j,k]))\n",
    "            results_name = 'rmse_{}_{}'.format(n_factors, reg_all)\n",
    "            np.savetxt(results_path + results_name + '.csv', rmses[i,j,:], delimiter=\",\")\n",
    "    return rmses\n",
    "\n",
    "rmses = train_SVD()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# create correct format\n",
    "def create_submission_dataframe(df_simple):\n",
    "    #print('Raw: \\n',df_simple.head())\n",
    "    df_simple[\"Id\"] = \"r\" + df_simple[\"iid\"].map(str) + \"_c\" +df_simple[\"uid\"].map(str)\n",
    "    df_simple[\"Prediction\"] = df_simple[\"est\"].clip(0,5)\n",
    "    df_submission = df_simple.drop([\"iid\",\"uid\",\"est\",\"details\",\"rui\"],1)\n",
    "    #print('Submission: \\n',df_submission.head()) \n",
    "    return df_submission\n",
    "\n",
    "def create_submition_csv(prediction, output_path):\n",
    "    df_svd = pd.DataFrame(prediction, columns=['uid', 'iid', 'rui', 'est', 'details'])    \n",
    "    df_svd_submission = create_submission_dataframe(df_svd)\n",
    "    df_svd_submission.to_csv(output_path, columns=[\"Id\",\"Prediction\"],index=False)\n",
    "    #print('Submission: \\n', df_svd_submission.head())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on whole data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS_BaselineOnly\n",
      "Estimating biases using als...\n",
      "0.99595235615\n",
      "SGD_BaselineOnly\n",
      "Estimating biases using sgd...\n",
      "1.00796981244\n",
      "ALS_pearson_baseline_user_based\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "0.960286964805\n",
      "ALS_pearson_baseline_item_based\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "0.960286964805\n",
      "pearson_baseline_user_based\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "0.898054902323\n",
      "rmse_list : \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rmse_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-20d0f8ce8403>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mrun_all_algorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rmse_list : \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmse_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'rmse_list' is not defined"
     ]
    }
   ],
   "source": [
    "def run_and_save(algo, fold_files, output_path):\n",
    "    fold_data=load_folds_data(fold_files)\n",
    "    mean_rmse, prediction = cross_validation(algo, fold_data)\n",
    "    create_submition_csv(prediction, output_path)\n",
    "    return mean_rmse\n",
    "\n",
    "def run_all_algorithm(fold_files, output_prefix):\n",
    "    \n",
    "    rmse_list = []\n",
    "    rmse_list.append(run_and_save(ALS_BaselineOnly(), fold_files, \"../submission/\"+output_prefix+\"ALS_BaselineOnly.csv\"))\n",
    "    rmse_list.append(run_and_save(SGD_BaselineOnly(), fold_files, \"../submission/\"+output_prefix+\"SGD_BaselineOnly.csv\"))\n",
    "    rmse_list.append(run_and_save(KNNBasic_ALS_pearson_baseline_user_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBasic_ALS_pearson_baseline_user_based.csv\"))\n",
    "    rmse_list.append(run_and_save(KNNBasic_ALS_pearson_baseline_item_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBasic_ALS_pearson_baseline_item_based.csv\"))\n",
    "    rmse_list.append(run_and_save(KNNBasic_pearson_baseline_user_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBasic_pearson_baseline_user_based.csv\"))\n",
    "    #rmse_list.append(run_and_save(KNNBasic_pearson_baseline_item_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBasic_pearson_baseline_item_based.csv\"))\n",
    "    #rmse_list.append(run_and_save(KNNBasic_cosine_user_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBasic_cosine_user_based.csv\"))\n",
    "    #rmse_list.append(run_and_save(KNNBasic_cosine_item_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBasic_cosine_item_based.csv\"))\n",
    "    #rmse_list.append(run_and_save(KNNBasic_pearson_user_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBasic_pearson_user_based.csv\"))\n",
    "    #rmse_list.append(run_and_save(KNNBasic_msd_user_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBasic_msd_user_based.csv\"))\n",
    "    #rmse_list.append(run_and_save(KNNBasic_msd_item_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBasic_msd_item_based.csv\"))\n",
    "    return rmse_list\n",
    "\n",
    "#fold_files=[('../data/blending_train_surprise.csv', '../data/data_train_surprise.csv')]\n",
    "#output_prefix='training_prediction_'\n",
    "#rmse_list=run_all_algorithm(fold_files, output_prefix)\n",
    "#print(\"rmse_list : \")\n",
    "#print(rmse_list)\n",
    "\n",
    "fold_files=[('../data/data_train_surprise.csv', '../data/sampleSubmission_surprise.csv')]\n",
    "output_prefix='submission_'\n",
    "rmse_list = run_all_algorithm(fold_files, output_prefix)\n",
    "print(\"rmse_list : \")\n",
    "print(rmse_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "objects = ('ALS_Baseline', \n",
    "           'SGD_Baseline', \n",
    "           'KNNBasic ALS pearson baseline user based', \n",
    "           'KNNBasic_ALS_pearson_baseline_item_based', \n",
    "           'KNNBasic_pearson_baseline_user_based', \n",
    "           'KNNBasic_pearson_baseline_item_based',\n",
    "           'KNNBasic_cosine_user_based',\n",
    "           'KNNBasic_cosine_item_based',\n",
    "           'KNNBasic_pearson_user_based',\n",
    "           'KNNBasic_msd_user_based',\n",
    "           'KNNBasic_msd_item_based')\n",
    "\n",
    "y_pos=np.arange(11)\n",
    "performance = [0.990, 0.98, 1.004, 0.990, 0.98, 1.004, 0.990, 0.98, 1.004, 0.990, 0.98]\n",
    " \n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Method')\n",
    " \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
