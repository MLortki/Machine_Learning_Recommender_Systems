{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "from surprise import Dataset, Reader\n",
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "        Load data from file path\n",
    "    \n",
    "        input:   file_path      -The input file path\n",
    "                \n",
    "        output:  data frame     -The loaded data frame from file path\n",
    "    \"\"\"\n",
    "    reader = Reader(line_format='item rating user', sep=',',skip_lines=1) \n",
    "    return Dataset.load_from_file(file_path, reader=reader)\n",
    "       \n",
    "def load_folds_data(fold_file_paths):\n",
    "    \"\"\"\n",
    "        Load folded data from folded file path\n",
    "    \n",
    "        input:   fold_file_paths  -The file paths of folded data\n",
    "                \n",
    "        output:  fold data frame  -The loaded data frames from folded file path\n",
    "    \"\"\"\n",
    "    reader = Reader(line_format='item rating user', sep=',',skip_lines=1) \n",
    "    return Dataset.load_from_folds(fold_file_paths, reader=reader)\n",
    "    \n",
    "train_data=load_data('../data/data_train_surprise.csv')\n",
    "fold_data=load_folds_data([('../data/blending_validation_surprise.csv', '../data/blending_test_surprise.csv')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from surprise.prediction_algorithms import NormalPredictor\n",
    "from surprise.prediction_algorithms import BaselineOnly\n",
    "from surprise.prediction_algorithms import KNNBasic\n",
    "from surprise.prediction_algorithms import KNNWithMeans\n",
    "from surprise.prediction_algorithms import KNNBaseline\n",
    "from surprise.prediction_algorithms import SVD\n",
    "#from surprise.prediction_algorithms import SVDpp\n",
    "#from surprise.prediction_algorithms import SlopeOne\n",
    "#from surprise.prediction_algorithms import co_clustering\n",
    "\n",
    "#params = {'n_factors':12,'n_epochs':20,'lr_all':0.005,'reg_all':0.0359,'biased':True}\n",
    "#params = {'n_factors':100,'n_epochs':20,'lr_all':0.005,'reg_all':0.0359,'biased':True}\n",
    "def my_SVD(n_factors, n_epochs, lr_all, reg_all, biased):\n",
    "    \"\"\"\n",
    "        SVD method\n",
    "    \n",
    "        input:  n_factors    - The number of factors\n",
    "                n_epochs     - The number of iteration of the SGD procedure\n",
    "                lr_all       - The learning rate for all parameters.\n",
    "                reg_all      - The regularization term for all parameters\n",
    "                biased       - Whether to use baselines (or biases)\n",
    "                \n",
    "        output: algo         - SVD algorithm based on specified parameters \n",
    "    \"\"\"\n",
    "    algo = SVD(n_factors=n_factors,n_epochs=n_epochs,lr_all=lr_all,reg_all=reg_all)\n",
    "    algo.bsl_options['biased'] = biased\n",
    "    return algo\n",
    "\n",
    "def ALS_BaselineOnly():\n",
    "    \"\"\"\n",
    "        BaselineOnly method using ALS\n",
    "        \n",
    "        input:  --      --\n",
    "        output: algo    -BaselineOnly method using ALS\n",
    "    \"\"\"\n",
    "    print(\"ALS_BaselineOnly\")\n",
    "    bsl_options = {'method': 'als',\n",
    "               'n_epochs': 5,\n",
    "               'reg_u': 15,\n",
    "               'reg_i': 10\n",
    "               } #1.0004\n",
    "    return BaselineOnly(bsl_options=bsl_options)\n",
    "\n",
    "def SGD_BaselineOnly():\n",
    "    \"\"\"\n",
    "        BaselineOnly method using ALS\n",
    "        \n",
    "        input:  --      --\n",
    "        output: algo    -BaselineOnly method using SGD\n",
    "    \"\"\"\n",
    "    print(\"SGD_BaselineOnly\")\n",
    "    bsl_options = {'method': 'sgd',\n",
    "               'learning_rate': .005,\n",
    "               'reg':0.02\n",
    "                } #1.0021\n",
    "    return BaselineOnly(bsl_options=bsl_options)\n",
    "\n",
    "\n",
    "def KNNBasic_ALS_pearson_baseline_user_based():\n",
    "    \"\"\"\n",
    "        BaselineOnly method using ALS\n",
    "        \n",
    "        input:  --      --\n",
    "        output: algo    -BaselineOnly method using SGD\n",
    "    \"\"\"\n",
    "    print(\"ALS_pearson_baseline_user_based\")\n",
    "    bsl_options = {'method': 'als',\n",
    "                    'n_epochs': 20,\n",
    "                    'user_based': True  # compute  similarities between users\n",
    "                   } \n",
    "    sim_options = {'name': 'pearson_baseline'}\n",
    "    return KNNBasic(bsl_options=bsl_options, sim_options=sim_options)\n",
    "\n",
    "\n",
    "def KNNBasic_ALS_pearson_baseline_item_based():\n",
    "    print(\"ALS_pearson_baseline_item_based\")\n",
    "    bsl_options = {'method': 'als',\n",
    "               'n_epochs': 20,\n",
    "                'user_based': False  # compute  similarities between users\n",
    "               } \n",
    "    sim_options = {'name': 'pearson_baseline'}\n",
    "    return KNNBasic(bsl_options=bsl_options, sim_options=sim_options)\n",
    "\n",
    "def KNNBasic_pearson_baseline_user_based():\n",
    "    print(\"pearson_baseline_user_based\")\n",
    "    sim_options = {'name': 'pearson_baseline',\n",
    "               'shrinkage': 0,  # no shrinkage\n",
    "                'user_based': True  # compute  similarities between users\n",
    "               } \n",
    "    return KNNBasic(sim_options=sim_options)\n",
    "\n",
    "def KNNBasic_pearson_baseline_item_based():\n",
    "    print(\"pearson_baseline_item_based\")\n",
    "    sim_options = {'name': 'pearson_baseline',\n",
    "               'shrinkage': 0,  # no shrinkage\n",
    "                'user_based': False  # compute  similarities between items\n",
    "               }\n",
    "    return KNNBasic(sim_options=sim_options)\n",
    "\n",
    "\n",
    "def KNNBasic_cosine_user_based():\n",
    "    print(\"cosine_user_based\")\n",
    "    sim_options = {'name': 'cosine',\n",
    "                   'user_based': True  # compute  similarities between users\n",
    "                   }\n",
    "    return KNNBasic(sim_options=sim_options)\n",
    "\n",
    "def KNNBasic_cosine_item_based():\n",
    "    print(\"cosine_item_based\")\n",
    "    sim_options = {'name': 'cosine',\n",
    "                   'user_based': False  # compute  similarities between items\n",
    "                   }\n",
    "    return KNNBasic(sim_options=sim_options)\n",
    "\n",
    "def KNNBasic_pearson_user_based():\n",
    "    print(\"pearson_user_based\")\n",
    "    sim_options = {'name': 'pearson',\n",
    "                'user_based': True  # compute  similarities between users\n",
    "               } \n",
    "    return KNNBasic(sim_options=sim_options)\n",
    "\n",
    "def KNNBasic_pearson_item_based():\n",
    "    print(\"pearson_item_based\")\n",
    "    sim_options = {'name': 'pearson',\n",
    "                'user_based': False  # compute  similarities between items\n",
    "               }\n",
    "    return KNNBasic(sim_options=sim_options)\n",
    "\n",
    "def KNNBasic_msd_user_based():\n",
    "    print(\"msd_user_based\")\n",
    "    sim_options = {'name': 'msd',\n",
    "                'user_based': True  # compute  similarities between users\n",
    "               } \n",
    "    return KNNBasic(sim_options=sim_options)\n",
    "\n",
    "def KNNBasic_msd_item_based():\n",
    "    print(\"msd_item_based\")\n",
    "    sim_options = {'name': 'msd',\n",
    "                'user_based': False  # compute  similarities between items\n",
    "               }\n",
    "    return KNNBasic(sim_options=sim_options)\n",
    "\n",
    "def KNNBaseline_pearson_baseline_user_based():\n",
    "    print(\"pearson_baseline_user_based\")\n",
    "    sim_options = {'name': 'pearson_baseline',\n",
    "               'shrinkage': 0,  # no shrinkage\n",
    "                'user_based': True  # compute  similarities between users\n",
    "               } \n",
    "    return KNNBaseline(sim_options=sim_options)\n",
    "\n",
    "def KNNBaseline_pearson_baseline_item_based():\n",
    "    print(\"pearson_baseline_item_based\")\n",
    "    sim_options = {'name': 'pearson_baseline',\n",
    "               'shrinkage': 0,  # no shrinkage\n",
    "                'user_based': False  # compute  similarities between items\n",
    "               }\n",
    "    return KNNBaseline(sim_options=sim_options)\n",
    "\n",
    "\n",
    "def KNNBaseline_cosine_user_based():\n",
    "    print(\"cosine_user_based\")\n",
    "    sim_options = {'name': 'cosine',\n",
    "                   'user_based': True  # compute  similarities between users\n",
    "                   }\n",
    "    return KNNBaseline(sim_options=sim_options)\n",
    "\n",
    "def KNNBaseline_cosine_item_based():\n",
    "    print(\"cosine_item_based\")\n",
    "    sim_options = {'name': 'cosine',\n",
    "                   'user_based': False  # compute  similarities between items\n",
    "                   }\n",
    "    return KNNBaseline(sim_options=sim_options)\n",
    "\n",
    "def KNNBaseline_pearson_user_based():\n",
    "    print(\"pearson_user_based\")\n",
    "    sim_options = {'name': 'pearson',\n",
    "                'user_based': True  # compute  similarities between users\n",
    "               } \n",
    "    return KNNBaseline(sim_options=sim_options)\n",
    "\n",
    "def KNNBaseline_pearson_item_based():\n",
    "    print(\"pearson_item_based\")\n",
    "    sim_options = {'name': 'pearson',\n",
    "                'user_based': False  # compute  similarities between items\n",
    "               }\n",
    "    return KNNBaseline(sim_options=sim_options)\n",
    "\n",
    "def KNNBaseline_msd_user_based():\n",
    "    print(\"msd_user_based\")\n",
    "    sim_options = {'name': 'msd',\n",
    "                'user_based': True  # compute  similarities between users\n",
    "               } \n",
    "    return KNNBaseline(sim_options=sim_options)\n",
    "\n",
    "def KNNBaseline_msd_item_based():\n",
    "    print(\"msd_item_based\")\n",
    "    sim_options = {'name': 'msd',\n",
    "                'user_based': False  # compute  similarities between items\n",
    "               }\n",
    "    return KNNBaseline(sim_options=sim_options)\n",
    "\n",
    "def KNNWithMeans_pearson_baseline_user_based():\n",
    "    print(\"pearson_baseline_user_based\")\n",
    "    sim_options = {'name': 'pearson_baseline',\n",
    "               'shrinkage': 0,  # no shrinkage\n",
    "                'user_based': True  # compute  similarities between users\n",
    "               } \n",
    "    return KNNWithMeans(sim_options=sim_options)\n",
    "\n",
    "def KNNWithMeans_pearson_baseline_item_based():\n",
    "    print(\"pearson_baseline_item_based\")\n",
    "    sim_options = {'name': 'pearson_baseline',\n",
    "               'shrinkage': 0,  # no shrinkage\n",
    "                'user_based': False  # compute  similarities between items\n",
    "               }\n",
    "    return KNNWithMeans(sim_options=sim_options)\n",
    "\n",
    "\n",
    "def KNNWithMeans_cosine_user_based():\n",
    "    print(\"cosine_user_based\")\n",
    "    sim_options = {'name': 'cosine',\n",
    "                   'user_based': True  # compute  similarities between users\n",
    "                   }\n",
    "    return KNNWithMeans(sim_options=sim_options)\n",
    "\n",
    "def KNNWithMeans_cosine_item_based():\n",
    "    print(\"cosine_item_based\")\n",
    "    sim_options = {'name': 'cosine',\n",
    "                   'user_based': False  # compute  similarities between items\n",
    "                   }\n",
    "    return KNNWithMeans(sim_options=sim_options)\n",
    "\n",
    "def KNNWithMeans_pearson_user_based():\n",
    "    print(\"pearson_user_based\")\n",
    "    sim_options = {'name': 'pearson',\n",
    "                'user_based': True  # compute  similarities between users\n",
    "               } \n",
    "    return KNNWithMeans(sim_options=sim_options)\n",
    "\n",
    "def KNNWithMeans_pearson_item_based():\n",
    "    print(\"pearson_item_based\")\n",
    "    sim_options = {'name': 'pearson',\n",
    "                'user_based': False  # compute  similarities between items\n",
    "               }\n",
    "    return KNNWithMeans(sim_options=sim_options)\n",
    "\n",
    "def KNNWithMeans_msd_user_based():\n",
    "    print(\"msd_user_based\")\n",
    "    sim_options = {'name': 'msd',\n",
    "                'user_based': True  # compute  similarities between users\n",
    "               } \n",
    "    return KNNWithMeans(sim_options=sim_options)\n",
    "\n",
    "def KNNWithMeans_msd_item_based():\n",
    "    print(\"msd_item_based\")\n",
    "    sim_options = {'name': 'msd',\n",
    "                'user_based': False  # compute  similarities between items\n",
    "               }\n",
    "    return KNNWithMeans(sim_options=sim_options)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train algorithm.\n",
    "import numpy as np\n",
    "from surprise.evaluate import evaluate\n",
    "from surprise.accuracy import rmse\n",
    "from surprise.dump import dump\n",
    "\n",
    "    \n",
    "def cross_validation(algo, fold_data):\n",
    "    \"\"\"\n",
    "        Cross validation on folded data by specified algorithm.\n",
    "    \n",
    "        input:   algo           -Learning algorithm method\n",
    "                fold_data      -List of (train_data, test_data) to do cross validation on it\n",
    "                \n",
    "        output:  rmse_mean      -The mean of rmse on all (train_data, test_data) in fold_data\n",
    "                prediction     -The prediction on test_data  \n",
    "    \"\"\"\n",
    "    \n",
    "    rmse_list = []\n",
    "    for trainset, testset in fold_data.folds():\n",
    "        #train the learning model on trainset using given algorithm\n",
    "        algo.train(trainset)\n",
    "        #predcit the result on testset using the trained model\n",
    "        prediction = algo.test(testset)\n",
    "        \n",
    "        #compute rmse\n",
    "        rmse_k = rmse(prediction, verbose=False)\n",
    "        print(rmse_k)\n",
    "        rmse_list.append(rmse_k)\n",
    "        #dump('../results/dump_algo', prediction, trainset, algo)\n",
    "    \n",
    "    \n",
    "    rmse_mean=np.mean(rmse_list)\n",
    "    print(rmse_mean)\n",
    "    return rmse_mean, prediction\n",
    "\n",
    "\n",
    "algo=KNNWithMeans_cosine_user_based()\n",
    "#fold_data=load_folds_data([('../data/blending_train_surprise.csv', '../data/data_train_surprise.csv')])\n",
    "train_data.split(n_folds=3)\n",
    "mean_rmse, prediction=cross_validation(algo, fold_data)\n",
    "print(\"mean_rmse {}\".format(mean_rmse))\n",
    "perf=evaluate(algo, fold_data, measures=['rmse'], with_dump=False, dump_dir=None, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Best parameters of SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_SVD():\n",
    "    \"\"\"\n",
    "        Find best parameters for SVD algorithm.\n",
    "       \n",
    "        input:   --      --\n",
    "                \n",
    "        output:  rmses   -The rmse list of running SVD on all parameters set \n",
    "    \"\"\"\n",
    "    \n",
    "    #initialize parameters\n",
    "    n_factors_range = np.array([10,15,20])    #number of columns\n",
    "    reg_all_range = np.logspace(-1.9,-1,10)   #The regularization term for all parameters\n",
    "    n_epochs_range = np.arange(10,60,10)      #The number of iteration of the SGD procedure.\n",
    "    lr_all=0.005                              #The learning rate for all parameters\n",
    "    biased=True                               #use baselines (or biases)\n",
    "    \n",
    "    \n",
    "    results_path = '../results/SGD_surprise/'\n",
    "    rmses = np.empty((len(n_factors_range),len(reg_all_range), len(n_epochs_range)))\n",
    "    \n",
    "    for i,n_factors in enumerate(n_factors_range):\n",
    "        print('testing with n_factors={}'.format(n_factors))\n",
    "        for j,reg_all in enumerate(reg_all_range):\n",
    "            print('testing with reg_all={}'.format(reg_all))\n",
    "            for k,n_epochs in enumerate(n_epochs_range):\n",
    "                print('testing with n_epochs={}'.format(n_epochs))\n",
    "                \n",
    "                #train SVD based on given parameters \n",
    "                algo=my_SVD(int(n_factors), n_epochs, lr_all, reg_all, biased)\n",
    "                \n",
    "                #cross validation on train_data and compute rmse\n",
    "                rmses[i,j,k],_=cross_validation(algo, train_data)\n",
    "                print('rmse={}'.format(rmses[i,j,k]))\n",
    "            \n",
    "            results_name = 'rmse_{}_{}'.format(n_factors, reg_all)\n",
    "            np.savetxt(results_path + results_name + '.csv', rmses[i,j,:], delimiter=\",\")\n",
    "    return rmses\n",
    "\n",
    "train_data.split(n_folds=3)\n",
    "rmses = train_SVD()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# create correct format\n",
    "def create_submission_dataframe(df_simple):\n",
    "    \"\"\"\n",
    "        Convert a data frame in simple format to a data framein submission format\n",
    "      \n",
    "        input:   df_simple      -Data frame in simple format\n",
    "                \n",
    "        output:  df_submission  -Data frame in submission  format\n",
    "    \"\"\"\n",
    "    \n",
    "    #print('Raw: \\n',df_simple.head())\n",
    "    df_simple[\"Id\"] = \"r\" + df_simple[\"iid\"].map(str) + \"_c\" +df_simple[\"uid\"].map(str)\n",
    "    df_simple[\"Prediction\"] = df_simple[\"est\"].clip(0,5)\n",
    "    df_submission = df_simple.drop([\"iid\",\"uid\",\"est\",\"details\",\"rui\"],1)\n",
    "    #print('Submission: \\n',df_submission.head()) \n",
    "    return df_submission\n",
    "\n",
    "def create_submition_csv(prediction, output_path):\n",
    "    \"\"\"save final predictions in output file in csv format\n",
    "    \n",
    "       input:   prediction      -The final prediction\n",
    "                output_path     -The submission file path\n",
    "       \n",
    "       output:  --              -- \n",
    "    \"\"\"\n",
    "    \n",
    "    df_svd = pd.DataFrame(prediction, columns=['uid', 'iid', 'rui', 'est', 'details'])    \n",
    "    df_svd_submission = create_submission_dataframe(df_svd)\n",
    "    df_svd_submission.to_csv(output_path, columns=[\"Id\",\"Prediction\"],index=False)\n",
    "    #print('Submission: \\n', df_svd_submission.head())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on whole data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_and_save(algo, fold_files, output_path):\n",
    "    \"\"\" \n",
    "        Learn the model on trainset based on given algorithm, \n",
    "        predict results on testset, \n",
    "        save the predictions in output file \n",
    "    \n",
    "        input:   algo            -Learning algorithm\n",
    "                fold_filse      -List of file paths of (trainset, testset)\n",
    "                output_path     -Output file path \n",
    "       \n",
    "        output:  mean_rmse       -The mean of rmse on (train_data, test_data) in fold_data\n",
    "       \n",
    "    \"\"\"\n",
    "    \n",
    "    #load train_data and test_data from fold_files list\n",
    "    fold_data=load_folds_data(fold_files)\n",
    "    #do cross validation on (train_data, test_data) and compute rmse and predictions\n",
    "    mean_rmse, prediction = cross_validation(algo, fold_data)\n",
    "    #save prediction in output file path\n",
    "    create_submition_csv(prediction, output_path)\n",
    "    return mean_rmse\n",
    "\n",
    "def run_all_algorithm(fold_files, output_prefix):\n",
    "    \"\"\" \n",
    "        Learn and predict result using diffrenet ML methods\n",
    "    \n",
    "       input:   \n",
    "                fold_filse      -List of file paths of (trainset, testset)\n",
    "                output_prefix   -The prefix of output file path \n",
    "       \n",
    "       output:  rmse_list       -The list of rmse on (train_data, test_data) in fold_data using different ML methods\n",
    "       \n",
    "    \"\"\"\n",
    "    \n",
    "    rmse_list = []\n",
    "    #rmse_list.append(run_and_save(ALS_BaselineOnly(), fold_files, \"../submission/\"+output_prefix+\"ALS_BaselineOnly.csv\"))\n",
    "    #rmse_list.append(run_and_save(SGD_BaselineOnly(), fold_files, \"../submission/\"+output_prefix+\"SGD_BaselineOnly.csv\"))\n",
    "    \n",
    "    #rmse_list.append(run_and_save(KNNBasic_ALS_pearson_baseline_user_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBasic_ALS_pearson_baseline_user_based.csv\"))\n",
    "    #rmse_list.append(run_and_save(KNNBasic_ALS_pearson_baseline_item_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBasic_ALS_pearson_baseline_item_based.csv\"))\n",
    "    \n",
    "    #rmse_list.append(run_and_save(KNNBasic_pearson_baseline_user_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBasic_pearson_baseline_user_based.csv\"))\n",
    "    #rmse_list.append(run_and_save(KNNBasic_pearson_baseline_item_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBasic_pearson_baseline_item_based.csv\"))\n",
    "    #rmse_list.append(run_and_save(KNNBasic_cosine_user_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBasic_cosine_user_based.csv\"))\n",
    "    #rmse_list.append(run_and_save(KNNBasic_cosine_item_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBasic_cosine_item_based.csv\"))\n",
    "    #rmse_list.append(run_and_save(KNNBasic_pearson_user_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBasic_pearson_user_based.csv\"))\n",
    "    #rmse_list.append(run_and_save(KNNBasic_msd_user_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBasic_msd_user_based.csv\"))\n",
    "    #rmse_list.append(run_and_save(KNNBasic_msd_item_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBasic_msd_item_based.csv\"))\n",
    "    \n",
    "    rmse_list.append(run_and_save(KNNWithMeans_pearson_baseline_user_based(), fold_files, \"../submission/\"+output_prefix+\"KNNWithMeans_pearson_baseline_user_based.csv\"))\n",
    "    #rmse_list.append(run_and_save(KNNWithMeans_pearson_baseline_item_based(), fold_files, \"../submission/\"+output_prefix+\"KNNWithMeans_pearson_baseline_item_based.csv\"))\n",
    "    rmse_list.append(run_and_save(KNNWithMeans_cosine_user_based(), fold_files, \"../submission/\"+output_prefix+\"KNNWithMeans_cosine_user_based.csv\"))\n",
    "    rmse_list.append(run_and_save(KNNWithMeans_cosine_item_based(), fold_files, \"../submission/\"+output_prefix+\"KNNWithMeans_cosine_item_based.csv\"))\n",
    "    rmse_list.append(run_and_save(KNNWithMeans_pearson_user_based(), fold_files, \"../submission/\"+output_prefix+\"KNNWithMeans_pearson_user_based.csv\"))\n",
    "    rmse_list.append(run_and_save(KNNWithMeans_msd_user_based(), fold_files, \"../submission/\"+output_prefix+\"KNNWithMeans_msd_user_based.csv\"))\n",
    "    rmse_list.append(run_and_save(KNNWithMeans_msd_item_based(), fold_files, \"../submission/\"+output_prefix+\"KNNWithMeans_msd_item_based.csv\"))\n",
    "    \n",
    "    rmse_list.append(run_and_save(KNNBaseline_pearson_baseline_user_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBaseline_pearson_baseline_user_based.csv\"))\n",
    "    #rmse_list.append(run_and_save(KNNBaseline_pearson_baseline_item_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBaseline_pearson_baseline_item_based.csv\"))\n",
    "    rmse_list.append(run_and_save(KNNBaseline_cosine_user_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBaseline_cosine_user_based.csv\"))\n",
    "    rmse_list.append(run_and_save(KNNBaseline_cosine_item_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBaseline_cosine_item_based.csv\"))\n",
    "    rmse_list.append(run_and_save(KNNBaseline_pearson_user_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBaseline_pearson_user_based.csv\"))\n",
    "    rmse_list.append(run_and_save(KNNBaseline_msd_user_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBaseline_msd_user_based.csv\"))\n",
    "    rmse_list.append(run_and_save(KNNBaseline_msd_item_based(), fold_files, \"../submission/\"+output_prefix+\"KNNBaseline_msd_item_based.csv\"))\n",
    "    \n",
    "    return rmse_list\n",
    "\n",
    "#learn all models on blending train set\n",
    "fold_files=[('../data/blending_train_surprise.csv', '../data/data_train_surprise.csv')]\n",
    "output_prefix='training_prediction_'\n",
    "rmse_list=run_all_algorithm(fold_files, output_prefix)\n",
    "print(\"rmse_list : \")\n",
    "print(rmse_list)\n",
    "\n",
    "#learn all models on whole train set and test on submition set\n",
    "fold_files=[('../data/data_train_surprise.csv', '../data/sampleSubmission_surprise.csv')]\n",
    "output_prefix='submission_'\n",
    "rmse_list = run_all_algorithm(fold_files, output_prefix)\n",
    "print(\"rmse_list : \")\n",
    "print(rmse_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "objects = ('ALS_Baseline', \n",
    "           'SGD_Baseline', \n",
    "           'KNNBasic ALS pearson baseline user based', \n",
    "           'KNNBasic_ALS_pearson_baseline_item_based', \n",
    "           'KNNBasic_pearson_baseline_user_based', \n",
    "           'KNNBasic_pearson_baseline_item_based',\n",
    "           'KNNBasic_cosine_user_based',\n",
    "           'KNNBasic_cosine_item_based',\n",
    "           'KNNBasic_pearson_user_based',\n",
    "           'KNNBasic_msd_user_based',\n",
    "           'KNNBasic_msd_item_based')\n",
    "\n",
    "y_pos=np.arange(11)\n",
    "rmses = [0.99595235614951694, 1.0079698124442131, 0.96028696480475029, \n",
    "         0.96028696480475029, 0.89805490232295371, 0.87317148180816972, \n",
    "         1.2899446549009248, 0.9458979465046482, 0.86038596275603796, 1.0858670369478618, 0.95430388112275488]\n",
    " \n",
    "plt.bar(y_pos, rmses, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Method')\n",
    " \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
