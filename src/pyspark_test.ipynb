{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run this cell only once! \n",
    "from pyspark import SparkConf, SparkContext\n",
    "conf = SparkConf() \\\n",
    "  .setAppName(\"MovieLensALS\") \\\n",
    "  .set(\"spark.executor.memory\", \"2g\")\n",
    "spark_context = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Count: 157\n"
     ]
    }
   ],
   "source": [
    "# For testing only.\n",
    "lines = spark_context.textFile(\"../README.md\")  \n",
    "words = lines.flatMap(lambda line: line.split())  \n",
    "count = words.count()  \n",
    "print(\"Word Count: \" + str(count)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Try recommender system\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# This is actually not necessary.\n",
    "def preprocess_data(data):\n",
    "    \"\"\"preprocessing the text data, conversion to numerical array format.\"\"\"\n",
    "    def deal_line(line):\n",
    "        pos = line[0]\n",
    "        rating = line[1]\n",
    "        row, col = pos.split(\"_\")\n",
    "        row = row.replace(\"r\", \"\")\n",
    "        col = col.replace(\"c\", \"\")\n",
    "        return int(row), int(col), float(rating)\n",
    "    \n",
    "    def statistics(data):\n",
    "        min_row = np.min(data[:,0])\n",
    "        max_row = np.max(data[:,0])\n",
    "        min_col = np.min(data[:,1]) \n",
    "        max_col = np.max(data[:,1])\n",
    "        return min_row, max_row, min_col, max_col\n",
    "\n",
    "    # parse each line\n",
    "    data_matrix = np.apply_along_axis(deal_line,axis=1,arr=data)\n",
    "\n",
    "    min_row, max_row, min_col, max_col = statistics(data_matrix)\n",
    "    ratings = sp.lil_matrix((int(max_row), int(max_col)))\n",
    "    for row, col, rating in data_matrix:\n",
    "        ratings[row - 1, col - 1] = rating\n",
    "    return ratings, data_matrix\n",
    "\n",
    "#data = pd.read_csv(\"../data/data_train.csv\")\n",
    "#__, data_new = preprocess_data(data.as_matrix().reshape((-1,2)))\n",
    "#train_pd = pd.DataFrame({'user':data_new[:,0],'item':data_new[:,1],'rating':data_new[:,2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load\n",
      "number of items: 10000, number of users: 1000\n",
      "train raw shape: (10000, 1000)\n"
     ]
    }
   ],
   "source": [
    "from helpers import load_data\n",
    "import scipy.sparse as sp\n",
    "print(\"load\")\n",
    "train_raw = load_data(\"../data/data_train.csv\")\n",
    "print(\"train raw shape:\",train_raw.shape)\n",
    "#df_panda = pd.DataFrame([(0, 0, 4.0), (0, 1, 2.0), (1, 1, 3.0), (1, 2, 4.0), (2, 1, 1.0), (2, 2, 5.0)],[\"user\", \"item\", \"rating\"])\n",
    "#df_panda = pd.DataFrame([(0, 0, 1, 1, 2, 2),(0,1,1,2,1,2),(4.0,2.0,3.0,4.0,1.0,5.0)],[\"user\", \"item\", \"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find\n",
      "panda dataframe\n",
      "sql dataframe\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "import pandas as pd\n",
    "print(\"find\")\n",
    "rows, cols, ratings = sp.find(train_raw) \n",
    "print(\"panda dataframe\")\n",
    "train_pd = pd.DataFrame({'item':rows+1,'user':cols+1,'rating':ratings})\n",
    "print(\"sql dataframe\")\n",
    "context = SQLContext(spark_context)\n",
    "train = context.createDataFrame(train_pd)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Apply alternating least squares\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "# TODO: split in test and training data for cross validation.\n",
    "\n",
    "#als = ALS(rank=30, maxIter=30,regParam=0.001,userCol=\"user\",itemCol=\"item\",ratingCol=\"rating\")\n",
    "als = ALS(rank=8, maxIter=50,regParam=0.065,userCol=\"user\",itemCol=\"item\",ratingCol=\"rating\")\n",
    "model = als.fit(train)\n",
    "print('solved for rank',model.rank)\n",
    "#print(model.userFactors.orderBy(\"id\").collect())\n",
    "#print(model.itemFactors.orderBy(\"id\").collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from helpers import load_data\n",
    "ratings = load_data('../data/sampleSubmission.csv')\n",
    "rows, cols, __ = sp.find(ratings)\n",
    "rows = rows + 1\n",
    "cols = cols + 1\n",
    "test_pd = pd.DataFrame({'item':rows,'user':cols})\n",
    "test = context.createDataFrame(test_pd)\n",
    "test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = context.createDataFrame([(1, 2), (1, 1), (2, 1)], [\"user\", \"item\"])\n",
    "test.show()\n",
    "x = [(int(y[0]),int(y[1])) for y in zip(rows,cols)]\n",
    "print(x[0:3])\n",
    "print(type(x[0][0]))\n",
    "test2 = context.createDataFrame(x,[\"item\", \"user\"])\n",
    "test2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test['user':1].select()\n",
    "#print(test2.filter(test2.user==1).collect())\n",
    "print(test2.where(test2.user==1).where(test2.item==37).collect())\n",
    "print(test2.where(test2.user==1).where(test2.item==7833).collect())\n",
    "print(test2.where(test2.user==1).where(test2.item==3986).collect())\n",
    "test2 = test2.sort('item','user')\n",
    "test2.show()\n",
    "test2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_df =  model.transform(test)\n",
    "predictions = sorted(predictions_df.collect(), key=lambda r: r[0])\n",
    "print(predictions[0])\n",
    "print(predictions[1])\n",
    "predictions_df.show()\n",
    "predictions_df =  model.transform(test2)\n",
    "predictions = sorted(predictions_df.collect(), key=lambda r: r[0])\n",
    "print(predictions[0])\n",
    "print(predictions[1])\n",
    "predictions_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_df = predictions_df.sort('item','user')\n",
    "predictions_pd = predictions_df.toPandas()\n",
    "predictions_pd[\"Id\"] = \"r\" + predictions_pd[\"item\"].map(str) + \"_c\" +predictions_pd[\"user\"].map(str)\n",
    "predictions_pd[\"Prediction\"] = predictions_pd[\"prediction\"].clip(0,5).round()\n",
    "predictions_pd_new = predictions_pd.drop([\"item\",\"user\",\"prediction\"],1)\n",
    "print(predictions_pd_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_path = '../results/submission_pyspark.csv'\n",
    "predictions_pd_new.to_csv(output_path,columns=[\"Id\",\"Prediction\"],index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "als.explainParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(predictions[0])\n",
    "print(model.userFactors.orderBy(\"id\").collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "#train = context.createDataFrame([(0, 0, 4.0), (0, 1, 2.0), (1, 1, 3.0), (1, 2, 4.0), (2, 1, 1.0), (2, 2, 5.0)],\n",
    "#                                 [\"user\", \"item\", \"rating\"])\n",
    "#test = context.createDataFrame([(0, 0), (0, 1), (1, 1), (1, 2), (2, 1), (2, 2)], [\"user\", \"item\"])\n",
    "\n",
    "als = ALS()\n",
    "model = als.fit(train)\n",
    "param_map = ParamGridBuilder() \\\n",
    "                    .addGrid(als.rank, [25]) \\\n",
    "                    .addGrid(als.maxIter, [20]) \\\n",
    "                    .addGrid(als.regParam, [0.0001]) \\\n",
    "                    .build()\n",
    "len(param_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('testing with {} parameters:'.format(len(param_map)))\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\")\n",
    "cross_validator = CrossValidator(estimator=als, estimatorParamMaps=param_map, evaluator=evaluator)\n",
    "models = cross_validator.fit(train)\n",
    "predicions =  models.bestModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('best model: \\n rank:',models.bestModel.rank)\n",
    "models.\n",
    "#print('maxIter:',models.bestModel.maxIter)\n",
    "#print('regParam: \\n',models.bestModel.regParam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "pySpark (Spark 1 .6.1)",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
